{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4faa9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from scipy.stats import entropy  #Kullback-Leibler divergence\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from scipy.signal import find_peaks\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6efe3aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run group_creation.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9500a773",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run topic_model_training_with_mathscinet.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7ef2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_folder=\"figs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0698902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def researcher_publication(publication):\n",
    "    publ_count = publication.groupby([\"mgp_id\"])['yw_publication_count'].apply(sum).reset_index(name='total_publ').copy()\n",
    "    mgpid2publ_count = dict(zip(publ_count[\"mgp_id\"], publ_count[\"total_publ\"]))\n",
    "    return mgpid2publ_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db9ad6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def publication_extract(group, publication):\n",
    "    grp_titles = None\n",
    "    if type(group)==list or type(group)==tuple:\n",
    "        grp_publ= publication[publication[\"mgp_id\"].isin(group)].copy()\n",
    "        grp_publ[\"yearwise_titles\"]= grp_publ[\"yearwise_titles\"].apply(lambda x : \" \".join(x))\n",
    "        yearwise_grp_publ = grp_publ.groupby([\"mgp_id\",\"publication_year\"])           ['yearwise_titles'].apply(list).reset_index(name='group_yearwise_titles').copy()\n",
    "        yearwise_grp_publ.sort_values('publication_year', inplace=True)\n",
    "        grp_titles = [(\" \".join(yearwise), year) for yearwise, year in yearwise_grp_publ[[\"group_yearwise_titles\",\"publication_year\"]].values]\n",
    "    else:\n",
    "        grp_publ= publication[publication[\"mgp_id\"]==group].copy()\n",
    "        grp_publ[\"yearwise_titles\"]= grp_publ[\"yearwise_titles\"].apply(lambda x : \" \".join(x))\n",
    "        yearwise_grp_publ = grp_publ.groupby([\"mgp_id\",\"publication_year\"])['yearwise_titles'].apply(list).reset_index(name='group_yearwise_titles').copy()\n",
    "        yearwise_grp_publ.sort_values('publication_year', inplace=True)\n",
    "        grp_titles = [(\" \".join(yearwise), year) for yearwise, year in yearwise_grp_publ[[\"group_yearwise_titles\",\"publication_year\"]].values]\n",
    "    return grp_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64c38cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constrained_publication_extract(group, publication, years):\n",
    "    grp_titles = None\n",
    "    if type(group)==list or type(group)==tuple:\n",
    "        grp_publ= publication[publication[\"mgp_id\"].isin(group)].copy()\n",
    "        tmp = []\n",
    "        advisor_publ = grp_publ[(grp_publ[\"mgp_id\"]==group[0]) & (grp_publ[\"publication_year\"] >= years[0])]\n",
    "        if advisor_publ.shape[0] > 0: \n",
    "            tmp.append(advisor_publ)\n",
    "        for grp_memeber, year in zip(group[1:],years[1:]):\n",
    "            advisees_publ = grp_publ[(grp_publ[\"mgp_id\"]==grp_memeber) & (grp_publ[\"publication_year\"] <= year)]\n",
    "            if advisees_publ.shape[0] > 0:\n",
    "                tmp.append(advisees_publ)\n",
    "        if len(tmp) > 0:\n",
    "            grp_data = pd.concat(tmp)\n",
    "            grp_data[\"yearwise_titles\"]= grp_data[\"yearwise_titles\"].apply(lambda x : \" \".join(x))\n",
    "            yearwise_grp_publ = grp_data.groupby([\"mgp_id\",\"publication_year\"])['yearwise_titles'].apply(list).reset_index(name='group_yearwise_titles').copy()\n",
    "            yearwise_grp_publ.sort_values('publication_year', inplace=True)\n",
    "            grp_titles = [(\" \".join(yearwise), year) for yearwise, year in yearwise_grp_publ[[\"group_yearwise_titles\",\"publication_year\"]].values]\n",
    "        else:\n",
    "            grp_titles = []\n",
    "    return grp_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "812c633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# publication = publicaton_data(stem_title=True)\n",
    "# mgp_nodes, mgp_edges = read_MGP()\n",
    "# mgpid2_cy = dict(zip(mgp_nodes[\"Id\"],mgp_nodes[\"Year\"]))\n",
    "# mgp_nodes[\"mathscinet_id\"] = mgp_nodes[\"MSN\"].apply(lambda x : x.rsplit(\"/\")[-1] if type(x)==str else x)\n",
    "# mathscinet2mgpid = dict(zip(mgp_nodes[\"mathscinet_id\"], mgp_nodes[\"Id\"]))\n",
    "# publication[\"mgp_id\"]=publication[\"author_id\"].map(mathscinet2mgpid)\n",
    "# publication[\"publication_year\"] =  pd.to_datetime(publication[\"publication_year\"])\n",
    "# publication[\"publication_year\"] = publication[\"publication_year\"].dt.year\n",
    "# filtered_groups, filtered_grp_member_cy, mgpid2publ_count, group_publication_titles = group_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d42d763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#publication[(publication[\"mgp_id\"]==3) & (publication[\"publication_year\"] >= 1939.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba190071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constrained_publication_extract((258,)+filtered_groups[258],publication, filtered_grp_member_cy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7e17bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_info(group_size=5):\n",
    "    mgp_nodes, mgp_edges = read_MGP()\n",
    "    mgpid2_cy = dict(zip(mgp_nodes[\"Id\"],mgp_nodes[\"Year\"]))\n",
    "    mgp_nodes[\"mathscinet_id\"] = mgp_nodes[\"MSN\"].apply(lambda x : x.rsplit(\"/\")[-1] if type(x)==str else x)\n",
    "    mathscinet2mgpid = dict(zip(mgp_nodes[\"mathscinet_id\"], mgp_nodes[\"Id\"]))\n",
    "    groups = group_Formation(mgp_nodes, mgp_edges)\n",
    "    filtered_groups = group_filter(groups, group_size)\n",
    "    publication = publicaton_data(\"final_mathscinet_publs_included_remaining_publ_processed.pkl\", stem_title=True)\n",
    "    #publication[\"yearwise_titles\"]= publication[\"yearwise_titles\"].apply(lambda x : \" \".join(x))\n",
    "    publication[\"mgp_id\"]=publication[\"author_id\"].map(mathscinet2mgpid)\n",
    "    publication[\"yw_publication_count\"] = publication[\"yearwise_titles\"].apply(lambda x:len(x))\n",
    "    mgpid2publ_count = researcher_publication(publication)\n",
    "    filtered_grp_member = [(k,)+v for k,v in filtered_groups.items()]\n",
    "    filtered_grp_member_cy = [[mgpid2_cy.get(member, None) for member in grp] for grp in  filtered_grp_member]         #completion year\n",
    "    publication[\"publication_year\"] =  pd.to_datetime(publication[\"publication_year\"])\n",
    "    publication[\"publication_year\"] = publication[\"publication_year\"].dt.year\n",
    "    group_publication_titles = {grp[0]: constrained_publication_extract(grp, publication, grp_cy) for grp, grp_cy in zip(filtered_grp_member, filtered_grp_member_cy)}\n",
    "    #group_publication_titles = {grp[0]: publication_extract(grp, publication) for grp in filtered_grp_member}\n",
    "    return filtered_groups, filtered_grp_member_cy, mgpid2publ_count, group_publication_titles, mgp_nodes, mgp_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1939e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_info_without_constraint(group_size=5):\n",
    "    mgp_nodes, mgp_edges = read_MGP()\n",
    "    mgpid2_cy = dict(zip(mgp_nodes[\"Id\"],mgp_nodes[\"Year\"]))\n",
    "    mgp_nodes[\"mathscinet_id\"] = mgp_nodes[\"MSN\"].apply(lambda x : x.rsplit(\"/\")[-1] if type(x)==str else x)\n",
    "    mathscinet2mgpid = dict(zip(mgp_nodes[\"mathscinet_id\"], mgp_nodes[\"Id\"]))\n",
    "    groups = group_Formation(mgp_nodes, mgp_edges)\n",
    "    filtered_groups = group_filter(groups, group_size)\n",
    "    publication = publicaton_data(\"final_mathscinet_publs_included_remaining_publ_processed.pkl\", stem_title=True)\n",
    "    #publication[\"yearwise_titles\"]= publication[\"yearwise_titles\"].apply(lambda x : \" \".join(x))\n",
    "    publication[\"mgp_id\"]=publication[\"author_id\"].map(mathscinet2mgpid)\n",
    "    publication[\"yw_publication_count\"] = publication[\"yearwise_titles\"].apply(lambda x:len(x))\n",
    "    mgpid2publ_count = researcher_publication(publication)\n",
    "    filtered_grp_member = [(k,)+v for k,v in filtered_groups.items()]\n",
    "    filtered_grp_member_cy = [[mgpid2_cy.get(member, None) for member in grp] for grp in  filtered_grp_member]         #completion year\n",
    "    publication[\"publication_year\"] =  pd.to_datetime(publication[\"publication_year\"])\n",
    "    publication[\"publication_year\"] = publication[\"publication_year\"].dt.year\n",
    "#     group_publication_titles = {grp[0]: constrained_publication_extract(grp, publication, grp_cy) for grp, grp_cy in zip(filtered_grp_member, filtered_grp_member_cy)} # with publication constraint for advisor and advisee \n",
    "    \n",
    "    group_publication_titles = {grp[0]: publication_extract(grp, publication) for grp in filtered_grp_member}\n",
    "    return filtered_groups, filtered_grp_member_cy, mgpid2publ_count, group_publication_titles, mgp_nodes, mgp_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab96758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_distributions_over_interval(group_publication, topic_model, id2word, preprocess, year_interval=2):\n",
    "    group_leader = group_publication[0]\n",
    "    publication  = group_publication[1]\n",
    "    first_pub_year = int(publication[0][1])\n",
    "    last_pub_year = int(publication[-1][1])\n",
    "    topic_dists = []\n",
    "    topic_years = []\n",
    "    for year in range(first_pub_year, last_pub_year+1, year_interval):\n",
    "        filter_publ = [publ[0] for publ in publication if int(publ[1]) >= year and int(publ[1]) < year+2]\n",
    "        #print(filter_publ)\n",
    "        if len(filter_publ) > 0: \n",
    "            topic_dist  =  list(predict(topic_model, id2word, preprocess, filter_publ))\n",
    "        else:\n",
    "            topic_dist = [[]]\n",
    "        topic_dists.append(topic_dist)\n",
    "        topic_years.append(year)\n",
    "    if len(topic_dists)==0:\n",
    "        print(group_leader)\n",
    "    return topic_years, topic_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48108fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_dist_over_interval(dist, i, rank=True, no_of_topics=15): #no_of_topics=15\n",
    "    topic_dist_interval = []\n",
    "    topic_rank = []\n",
    "    for interval_topic in dist:\n",
    "        temp_list=[]\n",
    "        for topic in interval_topic:\n",
    "            topic_dict = dict(topic)\n",
    "            temp_list.append([topic_dict.get(i, 0) for i in range(no_of_topics)])\n",
    "        avg = np.mean(np.array(temp_list), axis=0)\n",
    "        topic_dist_interval.append(avg)\n",
    "        if rank:\n",
    "            tmp_tuples = [(i, val)for i, val in enumerate(avg)]\n",
    "            sort_tuples = sorted(tmp_tuples, key=lambda x: x[1], reverse=True)\n",
    "            topic_rank.append(sort_tuples)#append([tup[0] for tup in sort_tuples])\n",
    "    topic_dist_interval= np.array(topic_dist_interval)\n",
    "    if len(topic_dist_interval) == 0:\n",
    "        print(i)\n",
    "    return (topic_dist_interval, topic_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bddf5ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_over_interval(dist, i, func):\n",
    "    metric_distance = []\n",
    "    if len(dist) > 1:\n",
    "        for p, q in zip(dist[0:-1],dist[1:]):\n",
    "            dist_distance = func(p, q)\n",
    "            metric_distance.append(dist_distance)\n",
    "    else:\n",
    "        dist_distance = func(dist[0])\n",
    "        metric_distance.append(dist_distance)\n",
    "    if len(metric_distance) == 0:\n",
    "        print(i)\n",
    "    return metric_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a24a1b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_metrics_over_interval(formated_dist[16088])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c528091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergance(p, q=None, epsilon=0.000000001):\n",
    "    p = p+epsilon\n",
    "    if type(q)== np.ndarray or type(q)== list:\n",
    "        q = q+epsilon\n",
    "    dist = entropy(p, q)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13a02562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a= np.zeros(10)\n",
    "# b= np.zeros(10)\n",
    "# kl_divergance(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e00aabf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def specific_plot_metric(mgp_id, year, metric_dist, researcher_id):\n",
    "    index =  [i for i, idd in enumerate(researcher_id) if idd==mgp_id]\n",
    "    if len(index) > 0:\n",
    "        index=index[0]\n",
    "        metric_dist = [[np.round(float(i), 2) for i in nested] for nested in metric_dist]\n",
    "        plt.figure(figsize=(8, 6), dpi=80)\n",
    "        print(index)\n",
    "        if len(year[index][1:]) > 0:\n",
    "            plt.plot(year[index][1:], metric_dist[index], label=f\"MGP ID : {researcher_id[index]}\", marker='o',                 markersize=5)\n",
    "        else:\n",
    "            plt.plot(year[index], metric_dist[index], label=f\"MGP ID : {researcher_id[index]}\", marker='o',                     markersize=5)\n",
    "        plt.ylabel(\"Distance\")#\n",
    "        plt.xlabel(\"Publication Year\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"{fig_folder}/{mgp_id}_distance.pdf\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Advisor (Group leader : {mgp_id}) not present in the filtered dataset\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f671ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def group_plot_metric(mgp_id, year, metric_dist, researcher_id):\n",
    "#     index =  [i for i, idd in enumerate(researcher_id) if idd==mgp_id]\n",
    "#     if len(index) > 0:\n",
    "#         index=index[0]\n",
    "#         metric_dist = [[np.round(float(i), 2) for i in nested] for nested in metric_dist]\n",
    "#         plt.figure(figsize=(8, 6), dpi=80)\n",
    "#         print(index)\n",
    "#         if len(year[index][1:]) > 0:\n",
    "#             plt.plot(year[index][1:], metric_dist[index], label=f\"MGP ID : {researcher_id[index]}\", marker='o',                 markersize=5)\n",
    "#         else:\n",
    "#             plt.plot(year[index], metric_dist[index], label=f\"MGP ID : {researcher_id[index]}\", marker='o',                     markersize=5)\n",
    "#         plt.ylabel(\"Distance\")#\n",
    "#         plt.xlabel(\"Publication Year\")\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         print(f\"Advisor (Group leader : {mgp_id}) not present in the filtered dataset\")\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c2e2fd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(year, metric_dist, researcher_id, num_researcher=5):\n",
    "    metric_dist = [[np.round(float(i), 2) for i in nested] for nested in metric_dist]\n",
    "    plt.figure(figsize=(8, 6), dpi=80)\n",
    "    for i in range(num_researcher):\n",
    "        index = random.choice(range(0, len(year)))\n",
    "        print(index)\n",
    "        if len(year[index][1:]) > 0:\n",
    "            plt.plot(year[index][1:], metric_dist[index], label=f\"MGP ID : {researcher_id[index]}\", marker='o', markersize=5)\n",
    "        else:\n",
    "            plt.plot(year[index], metric_dist[index], label=f\"MGP ID : {researcher_id[index]}\", marker='o', markersize=5)\n",
    "    plt.ylabel(\"KL(P || Q)\")\n",
    "    plt.xlabel(\"Publication Year\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{fig_folder}/KL_divergance.pdf\")\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f3cbb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_metric(year, metric_dist, researcher_id, num_researcher=5):\n",
    "    metric_dist = [[np.round(float(i), 2) for i in nested] for nested in metric_dist]\n",
    "    fig, axs = plt.subplots(2, num_researcher, figsize=(15, 6), facecolor='w', edgecolor='k')\n",
    "    fig.subplots_adjust(hspace = 0.5, wspace=0.2)\n",
    "    axs = axs.ravel()\n",
    "    for i in range(2*num_researcher):\n",
    "        index = random.choice(range(0, len(year)))\n",
    "        print(index)\n",
    "        if len(year[index][1:]) > 0:\n",
    "            year_mod  =  year[index][1:]\n",
    "            axs[i].plot(year_mod, metric_dist[index], label=f\"MGP ID : {researcher_id[index]}\", marker='o', markersize=5)\n",
    "        else:\n",
    "            year_mod  =  year[index]\n",
    "            axs[i].plot(year_mod, metric_dist[index], label=f\"MGP ID : {researcher_id[index]}\", marker='o', markersize=5)\n",
    "        axs[i].yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "        axs[i].set_ylabel(\"Distance\")#(\"KL(P || Q)\")\n",
    "        axs[i].set_xlabel(\"Publication Year\")\n",
    "        if len(year_mod) > 1 :\n",
    "            year_range = list(range(min(year_mod), max(year_mod)))\n",
    "        else:\n",
    "            year_range = year_mod\n",
    "        if len(year_range) > 10 and len(year_range) <= 40:\n",
    "            year_range = year_range[0::5]\n",
    "            add_year = year_range[-1]+5\n",
    "            year_range.append(add_year)\n",
    "        elif len(year_range) > 40 and len(year_range) <= 100:\n",
    "            year_range = year_range[0::10]\n",
    "            add_year = year_range[-1]+10\n",
    "            year_range.append(add_year)\n",
    "        elif len(year_range) <= 10 and len(year_range) > 1:\n",
    "            year_range = year_range[0::2]\n",
    "            add_year = year_range[-1]+2\n",
    "            year_range.append(add_year)\n",
    "        elif len(year_range) == 1:\n",
    "            pass\n",
    "            #year_range = year_range\n",
    "        else:\n",
    "            year_range = year_range[0::20]\n",
    "            add_year = year_range[-1]+20\n",
    "            year_range.append(add_year)\n",
    "        axs[i].set_xticks(year_range)\n",
    "        axs[i].legend()\n",
    "    fig.savefig(f\"{fig_folder}/Random_groups_distance_signals.pdf\")\n",
    "    plt.show()\n",
    "    return metric_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c62e166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_devergance(metric_std):\n",
    "    plt.plot(sorted(metric_std, reverse=True))\n",
    "    plt.xlabel(\"Researchers\")\n",
    "    plt.ylabel(\"Standard Deviation\")\n",
    "    plt.savefig(f\"{fig_folder}/topic_divergance_distribution.pdf\")\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c42520eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_jaccard_index(topic_order1, topic_order2 = [], top=5):\n",
    "    assert len(topic_order1) > 1 or len(topic_order2) > 1\n",
    "    topic_order1 = topic_order1[:top]\n",
    "    topic_order2 = topic_order2[:top]\n",
    "    size1 =  len(topic_order1)\n",
    "    size2 =  len(topic_order2)\n",
    "    modified_order1 = [inx for i, inx in enumerate(topic_order1) for j in range(size1-(i))]\n",
    "    modified_order2 = [inx for i, inx in enumerate(topic_order2) for j in range(size2-(i))]\n",
    "    #print(modified_order1)\n",
    "    #print(modified_order2)\n",
    "    common_elements = list(set(modified_order1).intersection(modified_order2))\n",
    "    distinct_elements = list(set(modified_order1).union(modified_order2))\n",
    "    counter1 = Counter(modified_order1)\n",
    "    counter2 = Counter(modified_order2)\n",
    "    common_element_count = sum(min(counter1[elem], counter2[elem]) for elem in common_elements)\n",
    "    #print(common_element_count)\n",
    "    total_element_count =  sum(max(counter1[elem], counter2[elem]) for elem in distinct_elements)\n",
    "    #print(total_element_count)\n",
    "    mod_jaccard_index =  common_element_count/total_element_count\n",
    "    dist = 1-mod_jaccard_index\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c9356a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hurst_exponent(time_series, max_lag=20):\n",
    "    \"\"\"Returns the Hurst Exponent of the time series\"\"\"\n",
    "    lags = range(2, max_lag)\n",
    "    \n",
    "    # variances of the lagged differences\n",
    "    tau = [np.std(np.subtract(time_series[lag:], time_series[:-lag])) for lag in lags]\n",
    "    \n",
    "    # calculate the slope of the log plot -> the Hurst Exponent\n",
    "    reg = np.polyfit(np.log(lags), np.log(tau), 1)\n",
    "    \n",
    "    return reg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "414869cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_lowest(metrics, group_head_id, zero_include = True,top=10):\n",
    "    res_metric        = [(head, metric) for head, metric in zip(group_head_id, metrics)]\n",
    "    sorted_res_metric = sorted(res_metric, key= lambda x: x[1])\n",
    "    #print(sorted_res_metric[0:5])\n",
    "    if zero_include: \n",
    "        res = [i[0] for i in sorted_res_metric]\n",
    "    else:\n",
    "        res = [i[0] for i in sorted_res_metric if i[1] > 0]\n",
    "    persistent_res = res[:top] #if i[1] > 0\n",
    "    anti_persistent_res = res[-top:] #if i[1] > 0\n",
    "    return persistent_res, anti_persistent_res[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0114d459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names(mgp_nodes, mgp_indices):\n",
    "    details = [tuple(mgp_nodes[mgp_nodes[\"Id\"]==index][[\"Id\",\"Name\",\"University\", \"Country\"]].values[0]) \n",
    "               for index in mgp_indices]\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a88cb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publication count : 2209351\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    print(\"Running topic influence base\")\n",
    "    filtered_groups, filtered_grp_member_cy, mgpid2publ_count, group_publication_titles, mgp_nodes, mgp_edges=group_info(5) # with publication constraint for advisor and advisee\n",
    "#     filtered_groups, filtered_grp_member_cy, mgpid2publ_count, group_publication_titles, mgp_nodes, mgp_edges=\n",
    "#     group_info_without_constraint(5)\n",
    "    print(f\"Total filtered groups: {len(filtered_groups)}\")\n",
    "    lda_model, id2word = load_topic_model()\n",
    "    lda_model.minimum_probability = 0.0\n",
    "    group_head_id = [k for k,v in group_publication_titles.items() if len(v) > 0]\n",
    "    topic_distribution_year = [(topic_distributions_over_interval((k,v), lda_model, id2word,prepare_text_for_lda)) \n",
    "                               for k,v in group_publication_titles.items() if len(v) > 0]\n",
    "    interval_start_year = [i[0] for i in topic_distribution_year]\n",
    "    topic_distribution  = [i[1] for i in topic_distribution_year]\n",
    "    aggregated_distribution_topic_rank = [aggregate_dist_over_interval(dist, i) \n",
    "                                          for i, dist in enumerate(topic_distribution)]\n",
    "    aggregated_distribution = [elem[0] for elem in aggregated_distribution_topic_rank]\n",
    "    topic_with_value        = [elem[1] for elem in aggregated_distribution_topic_rank]\n",
    "    topic_rank = [[[value[0] for value in interval] for interval in researcher] \n",
    "                  for researcher in topic_with_value] #changed\n",
    "    metric_distance_kl = [get_distance_over_interval(dist, i, kl_divergance) \n",
    "                          for i, dist in enumerate(aggregated_distribution)]\n",
    "    metric_distance_tau = [get_distance_over_interval(rank, i, modified_jaccard_index) \n",
    "                           for i, rank in enumerate(topic_rank)]\n",
    "    norm_distance_kl    = [list(np.array(metrics)/sum(metrics)) if sum(metrics) > 0.0 else metrics \n",
    "                           for metrics in metric_distance_kl]\n",
    "    norm_distance_tau   = [list(np.array(metrics)/sum(metrics)) if sum(metrics) > 0.0 else metrics \n",
    "                           for metrics in metric_distance_tau]\n",
    "    assert len(interval_start_year) == len(aggregated_distribution) == len(metric_distance_kl) == len(metric_distance_tau) == len(group_head_id) == len(norm_distance_kl)==len(norm_distance_tau)\n",
    "    print(f\"Number of groups (Publication count > 0): {len(group_head_id)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0412041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mgp_nodes, mgp_edges = read_MGP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3d5aff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # standard deviation\n",
    "# metric_std_tau = [np.std(interval)/len(interval) for interval in norm_distance_tau]\n",
    "# metric_peaks_tau = [len(find_peaks(interval)[0])/len(interval) for interval in norm_distance_tau]\n",
    "# metric_hurst_exp_tau = [get_hurst_exponent(interval)/len(interval) for interval in norm_distance_tau]\n",
    "# metric_hurst_exp_tau = [i for i in metric_hurst_exp_tau if ~np.isnan(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "68585343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # with Kullback–Leibler divergence (KL-Divergance)\n",
    "# metric_std_kl = [np.std(interval)/len(interval) for interval in norm_distance_kl]\n",
    "# metric_peaks_kl = [len(find_peaks(interval)[0])/len(interval) for interval in norm_distance_kl]\n",
    "# metric_hurst_exp_kl = [get_hurst_exponent(interval)/len(interval) for interval in norm_distance_kl]\n",
    "# metric_hurst_exp_kl = [i for i in metric_hurst_exp_kl if ~np.isnan(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9fffe888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# persistent_res, anti_persistent_res = find_top_lowest(metric_std_tau, group_head_id, top=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f96373c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# persistent_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "45b7bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_names(mgp_nodes, persistent_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7fd66b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_names(mgp_nodes, anti_persistent_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6d0a2a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anti_persistent_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "df776329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific_plot_metric(284, interval_start_year, norm_distance_kl, group_head_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0937a6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific_plot_metric(151149, interval_start_year, norm_distance_kl, group_head_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "434d0e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_publication_titles[151149]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8138128",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic_rank[10269]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "202d273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#norm_distance_tau[10269]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "215c652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounded_metric_dist = subplot_metric(interval_start_year, norm_distance_tau, group_head_id, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "318e1283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounded_metric_dist = subplot_metric(interval_start_year, norm_distance_kl, group_head_id, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "adf8ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_metric(interval_start_year, norm_distance_tau, group_head_id, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0ce2bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_metric(interval_start_year, norm_distance_kl, group_head_id, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bdb002d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_devergance(sorted(metric_std_tau, reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ad7f6d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _= plt.hist(metric_std_tau, bins=100)\n",
    "# plt.title(\"Deviation distribution\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8d235871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(sorted(metric_peaks_tau,reverse=True))\n",
    "# plt.ylabel(\"No. of peaks\")\n",
    "# plt.xlabel(\"Researchers index\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "363d5b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _= plt.hist(metric_peaks_tau, bins=100)\n",
    "# plt.title(\"Peak Distribution\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5f2f3f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(sorted(metric_hurst_exp_tau, reverse=True))\n",
    "# plt.ylabel(\"hurst exponent value\")\n",
    "# plt.xlabel(\"Researchers index\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e55d8a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _= plt.hist(metric_hurst_exp_tau, bins=100)\n",
    "# plt.title(\"Hurst exponent distribution\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "cc30f9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic_order1 = [25,10, 15, 13 ,1]\n",
    "# topic_order2 = []\n",
    "# modified_jaccard_index(topic_order1, topic_order2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "69485064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from hurst import compute_Hc, random_walk\n",
    "#metric_hurst_exp = [compute_Hc(group, kind='change', simplified=True) for group in norm_metric_distance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "d708972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(year[2243],\"\\n\",year[14984],\"\\n\",year[13020],\"\\n\",year[581],\"\\n\",year[16228])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "28f9c32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group_publ_zero = [k for k,v in group_publication_titles.items() if len(v) < 2] \n",
    "#number of groups with zero or one publication = 1299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "15a28069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(group_publ_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b632c4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lda_model.show_topic(23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c394c7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(predict(lda_model, id2word, prepare_text_for_lda, ['finit strain analysi elast theori', 'stress orthotrop elast layer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa05171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mgp_edges[mgp_edges[\"advisor\"]==210603]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8884f989",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.sample(list(filtered_groups.keys()),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07963f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mgp_nodes[\"MSN\"].apply(lambda x : x.rsplit(\"/\")[-1] if type(x)==str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6015e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mathscinet2mgpid = dict(zip(mgp_nodes[\"mathscinet_id\"], mgp_nodes[\"Id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59880d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for indx,i in enumerate(range(1939,2013,2)):\n",
    "#     print(indx, i, i+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eee1779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = (258, [('finit strain analysi elast theori', '1939'),\n",
    "#  ('stress orthotrop elast layer', '1940'),\n",
    "#  ('bend clamp plate', '1944'),\n",
    "#  ('bend clamp plate', '1947'),\n",
    "#  ('flow viscous fluid slowli rotat eccentr cylind', '1948'),\n",
    "#  ('center flexur beam triangular section', '1949'),\n",
    "#  ('involut conic orthogon matric', '1949'),\n",
    "#  ('center flexur triangular beam', '1950'),\n",
    "#  ('indent semi infinit medium axial symmetr rigid punch', '1952'),\n",
    "#  ('solut dual integr equat plane strain boussinesq problem orthotrop medium',\n",
    "#   '1953'),\n",
    "#  ('common eigenvector commut oper', '1956'),\n",
    "#  ('schwartz theori distribut', '1957'),\n",
    "#  ('geometr note cayley transform', '1971'),\n",
    "#  ('rotat matric', '1999'),\n",
    "#  ('spatial decay cross diffus problem bound optim constant inequ ladyzhenskaya solonnikov',\n",
    "#   '2007'),\n",
    "#  ('blow phenomena nonlinear parabol system blow phenomena nonlinear parabol problem blow parabol problem robin boundari condit continu depend soret coeffici doubl diffus convect darci flow bound blow time nonlinear parabol problem spatial decay bound doubl diffus convect brinkman flow',\n",
    "#   '2008'),\n",
    "#  ('ill pose problem heat equat decay keller segel chemotaxi model bound blow time heat equat nonlinear boundari condit lower bound blow time nonlinear parabol problem',\n",
    "#   '2009'),\n",
    "#  ('blow phenomena semilinear heat equat nonlinear boundari condit blow phenomena semilinear heat equat nonlinear boundari condit ii blow decay criteria model chemotaxi',\n",
    "#   '2010'),\n",
    "#  ('blow class non linear parabol problem time depend coeffici robin type boundari condit blow phenomena parabol problem time depend coeffici neumann boundari condit blow phenomena class parabol system time depend coeffici lower bound blow model chemotaxi',\n",
    "#   '2012'),\n",
    "#  ('blow phenomena parabol problem time depend coeffici dirichlet boundari condit',\n",
    "#   '2013')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90582c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#publication = publicaton_data(stem_title=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
