{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44cd9765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import nan\n",
    "from main_util_func import *\n",
    "import stellargraph as sg\n",
    "from stellargraph import IndexedArray\n",
    "from stellargraph.mapper import PaddedGraphGenerator\n",
    "from stellargraph.layer import GCNSupervisedGraphClassification\n",
    "from stellargraph import StellarGraph\n",
    "\n",
    "from sklearn import model_selection\n",
    "#from IPython.display import display, HTML\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "287e239f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False #autocomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71584568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_read():\n",
    "    data_loc = './inter_files/input-output-data1.csv'\n",
    "    data = pd.read_csv(data_loc, sep=',', lineterminator=\"\\n\", low_memory=False)\n",
    "    data['input_nodes_sequence'] = data['input_nodes_sequence'].apply(lambda x : eval(x))\n",
    "    data['output_seq'] = data['output_seq'].apply(lambda x : eval(x))\n",
    "    data['output'] = data['output_seq'].apply(lambda x : x[-1])\n",
    "    data['first_year']= data['input_years_sequence'].apply(lambda x:eval(x)[1]) #new\n",
    "    data['flag'] = data['first_year']+15 <= 2021 #new\n",
    "    data = data[data['flag']==True].copy() #new\n",
    "    node_seq_len = [len(a) for a in data['input_nodes_sequence'].values]\n",
    "    max_len = max(node_seq_len)\n",
    "    return data, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ac508b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[\"output_seq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56ef7375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphs_data(embeddings, data):\n",
    "    graph_labels= []\n",
    "    graphs= []\n",
    "    for head, family, family_edge, output in data[[\"Id\",\"input_nodes_sequence\",\"input_edgelist\",\"output_seq\"]].values:\n",
    "        node_feat=[]\n",
    "        source = []\n",
    "        target = []\n",
    "        if type(family)==str:\n",
    "            family=eval(family)\n",
    "        family_edge = eval(family_edge)\n",
    "        for a in family:\n",
    "            node_feat.append(embeddings[a])\n",
    "        node_feat = np.array(node_feat)\n",
    "        node_feat_inx = IndexedArray(node_feat, index=family)\n",
    "        for edge in family_edge:\n",
    "            source.append(edge[0])\n",
    "            target.append(edge[1])\n",
    "        family_edges = pd.DataFrame({\"source\":source, \"target\": target})\n",
    "        graph = sg.StellarDiGraph(node_feat_inx, family_edges)\n",
    "        graphs.append(graph)\n",
    "        graph_labels.append(output)\n",
    "    return graphs, graph_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81e9d1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(graphs, data):\n",
    "    assert len(graphs)== data.shape[0]\n",
    "    index=np.random.randint(0,len(graphs))\n",
    "    print(f\"Edges: {eval(data['input_edgelist'].values[index])}\")\n",
    "    print(f\"Nodes: {data['input_nodes_sequence'].values[index]}\")\n",
    "    print(f\"Head: {data['Id'].values[index]}\")\n",
    "    print(graphs[index].info())\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ef34021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_data(data, sy, ey, tsy, tey):\n",
    "    start_date = sy\n",
    "    end_date = ey\n",
    "    test_start_date = tsy\n",
    "    test_end_date = tey\n",
    "    train_data = data[(data['Year'] > start_date) & (data['Year'] <= end_date)].copy()\n",
    "    test_data = data[(data['Year'] > test_start_date) & (data['Year'] <= test_end_date)].copy()\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb8788a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_regression_model(generator, lr=0.001):\n",
    "    gc_model = GCNSupervisedGraphClassification(\n",
    "        layer_sizes=[64, 64],\n",
    "        activations=[\"relu\", \"relu\"],\n",
    "        generator=generator,\n",
    "        dropout=0.2,\n",
    "    )\n",
    "    x_inp, x_out = gc_model.in_out_tensors()\n",
    "    predictions = Dense(units=32, activation=\"relu\")(x_out)\n",
    "    predictions = Dense(units=16, activation=\"relu\")(predictions)\n",
    "    predictions = Dense(units=1)(predictions)\n",
    "\n",
    "    # Let's create the Keras model and prepare it for training\n",
    "    model = Model(inputs=x_inp, outputs=predictions)\n",
    "    model.compile(optimizer=Adam(lr), loss=MeanSquaredError(), metrics=[\"mse\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ef15e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_gen, val_gen, es, epochs):\n",
    "    history = model.fit(\n",
    "        train_gen, epochs=epochs, validation_data=val_gen, callbacks=[es],\n",
    "    )\n",
    "    # calculate performance on the test data and return along with history\n",
    "    val_metrics = model.evaluate(val_gen, verbose=0)\n",
    "    val_mse = val_metrics[model.metrics_names.index(\"mse\")]\n",
    "\n",
    "    return history, val_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "149dc60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generators(generator, train_index, val_index, graph_labels, batch_size):\n",
    "    \n",
    "    train_gen = generator.flow(\n",
    "        train_index, targets=graph_labels[train_index], batch_size=batch_size\n",
    "    )\n",
    "    val_gen = generator.flow(\n",
    "        val_index, targets=graph_labels[val_index], batch_size=batch_size\n",
    "    )\n",
    "    return train_gen, val_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31def5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generator(test_graphs, test_graph_labels, batch_size=32):\n",
    "    test_gen_pad =  PaddedGraphGenerator(graphs=test_graphs)\n",
    "    test_index = range(len(test_graphs))\n",
    "    test_gen   = test_gen_pad.flow(test_index, targets=test_graph_labels[test_index], batch_size=batch_size)\n",
    "    return test_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e106413c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started\n",
      "train data: 19988, test data: 4501\n",
      "train output: [4.45943162 1.5849625  1.         3.169925   2.80735492]\n",
      "test output: [4.         3.32192809 1.         2.32192809 3.45943162]\n",
      "Epoch 1/200\n",
      "438/438 [==============================] - 7s 16ms/step - loss: 1.7236 - mse: 1.7236 - val_loss: 0.8110 - val_mse: 0.8110\n",
      "Epoch 2/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.8400 - mse: 0.8400 - val_loss: 0.6927 - val_mse: 0.6927\n",
      "Epoch 3/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.7084 - mse: 0.7084 - val_loss: 0.6508 - val_mse: 0.6508\n",
      "Epoch 4/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.6356 - mse: 0.6356 - val_loss: 0.7911 - val_mse: 0.7911\n",
      "Epoch 5/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.5893 - mse: 0.5893 - val_loss: 0.5259 - val_mse: 0.5259\n",
      "Epoch 6/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.5308 - mse: 0.5308 - val_loss: 0.4604 - val_mse: 0.4604\n",
      "Epoch 7/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.4927 - mse: 0.4927 - val_loss: 0.4613 - val_mse: 0.4613\n",
      "Epoch 8/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.4472 - mse: 0.4472 - val_loss: 0.5205 - val_mse: 0.5205\n",
      "Epoch 9/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.4153 - mse: 0.4153 - val_loss: 0.5005 - val_mse: 0.5005\n",
      "Epoch 10/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.3948 - mse: 0.3948 - val_loss: 0.4353 - val_mse: 0.4353\n",
      "Epoch 11/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.3752 - mse: 0.3752 - val_loss: 0.5218 - val_mse: 0.5218\n",
      "Epoch 12/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.3579 - mse: 0.3579 - val_loss: 0.4522 - val_mse: 0.4522\n",
      "Epoch 13/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.3449 - mse: 0.3449 - val_loss: 0.3812 - val_mse: 0.3812\n",
      "Epoch 14/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.3287 - mse: 0.3287 - val_loss: 0.3386 - val_mse: 0.3386\n",
      "Epoch 15/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.3174 - mse: 0.3174 - val_loss: 0.4008 - val_mse: 0.4008\n",
      "Epoch 16/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.2992 - mse: 0.2992 - val_loss: 0.3441 - val_mse: 0.3441\n",
      "Epoch 17/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.3021 - mse: 0.3021 - val_loss: 0.3915 - val_mse: 0.3915\n",
      "Epoch 18/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2916 - mse: 0.2916 - val_loss: 0.3628 - val_mse: 0.3628\n",
      "Epoch 19/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2893 - mse: 0.2893 - val_loss: 0.3631 - val_mse: 0.3631\n",
      "Epoch 20/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2786 - mse: 0.2786 - val_loss: 0.3484 - val_mse: 0.3484\n",
      "Epoch 21/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2839 - mse: 0.2839 - val_loss: 0.3194 - val_mse: 0.3194\n",
      "Epoch 22/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2670 - mse: 0.2670 - val_loss: 0.3595 - val_mse: 0.3595\n",
      "Epoch 23/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2638 - mse: 0.2638 - val_loss: 0.3362 - val_mse: 0.3362\n",
      "Epoch 24/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2631 - mse: 0.2631 - val_loss: 0.3521 - val_mse: 0.3521\n",
      "Epoch 25/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2632 - mse: 0.2632 - val_loss: 0.3119 - val_mse: 0.3119\n",
      "Epoch 26/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.2570 - mse: 0.2570 - val_loss: 0.3576 - val_mse: 0.3576\n",
      "Epoch 27/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.2518 - mse: 0.2518 - val_loss: 0.3388 - val_mse: 0.3388\n",
      "Epoch 28/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.2524 - mse: 0.2524 - val_loss: 0.3367 - val_mse: 0.3367\n",
      "Epoch 29/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2556 - mse: 0.2556 - val_loss: 0.3385 - val_mse: 0.3385\n",
      "Epoch 30/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.2442 - mse: 0.2442 - val_loss: 0.3046 - val_mse: 0.3046\n",
      "Epoch 31/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.2479 - mse: 0.2479 - val_loss: 0.3309 - val_mse: 0.3309\n",
      "Epoch 32/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2496 - mse: 0.2496 - val_loss: 0.3282 - val_mse: 0.3282\n",
      "Epoch 33/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2384 - mse: 0.2384 - val_loss: 0.3127 - val_mse: 0.3127\n",
      "Epoch 34/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2408 - mse: 0.2408 - val_loss: 0.3324 - val_mse: 0.3324\n",
      "Epoch 35/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2416 - mse: 0.2416 - val_loss: 0.3493 - val_mse: 0.3493\n",
      "Epoch 36/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2354 - mse: 0.2354 - val_loss: 0.3164 - val_mse: 0.3164\n",
      "Epoch 37/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2333 - mse: 0.2333 - val_loss: 0.3069 - val_mse: 0.3069\n",
      "Epoch 38/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2328 - mse: 0.2328 - val_loss: 0.3128 - val_mse: 0.3128\n",
      "Epoch 39/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2329 - mse: 0.2329 - val_loss: 0.3130 - val_mse: 0.3130\n",
      "Epoch 40/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.3582 - val_mse: 0.3582\n",
      "Epoch 41/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.2265 - mse: 0.2265 - val_loss: 0.3459 - val_mse: 0.3459\n",
      "Epoch 42/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.2314 - mse: 0.2314 - val_loss: 0.3409 - val_mse: 0.3409\n",
      "Epoch 43/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.2271 - mse: 0.2271 - val_loss: 0.3259 - val_mse: 0.3259\n",
      "Epoch 44/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.3307 - val_mse: 0.3307\n",
      "Epoch 45/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2222 - mse: 0.2222 - val_loss: 0.3435 - val_mse: 0.3435\n",
      "Epoch 46/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2197 - mse: 0.2197 - val_loss: 0.3241 - val_mse: 0.3241\n",
      "Epoch 47/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.2181 - mse: 0.2181 - val_loss: 0.3165 - val_mse: 0.3165\n",
      "Epoch 48/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2247 - mse: 0.2247 - val_loss: 0.3219 - val_mse: 0.3219\n",
      "Epoch 49/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2194 - mse: 0.2194 - val_loss: 0.3223 - val_mse: 0.3223\n",
      "Epoch 50/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.2168 - mse: 0.2168 - val_loss: 0.3311 - val_mse: 0.3311\n",
      "Epoch 51/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.2140 - mse: 0.2140 - val_loss: 0.3139 - val_mse: 0.3139\n",
      "Epoch 52/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.2148 - mse: 0.2148 - val_loss: 0.3361 - val_mse: 0.3361\n",
      "Epoch 53/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.2159 - mse: 0.2159 - val_loss: 0.3432 - val_mse: 0.3432\n",
      "Epoch 54/200\n",
      "438/438 [==============================] - 6s 13ms/step - loss: 0.2136 - mse: 0.2136 - val_loss: 0.3108 - val_mse: 0.3108\n",
      "Epoch 55/200\n",
      "438/438 [==============================] - 6s 14ms/step - loss: 0.2177 - mse: 0.2177 - val_loss: 0.3369 - val_mse: 0.3369\n",
      "Testing\n",
      "141/141 [==============================] - 2s 11ms/step - loss: 0.3266 - mse: 0.3266\n",
      "val:0.30460596084594727, test error:0.3265707790851593\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"started\")\n",
    "#     parser = argparse.ArgumentParser(description='input output for m1 and m2')\n",
    "#     parser.add_argument('-sy','--start_date', help='train start year',required=True)\n",
    "#     parser.add_argument('-ey','--end_date', help='train end year', required=True)\n",
    "#     parser.add_argument('-tsy','--test_start_date', help='test start year', required=True)\n",
    "#     parser.add_argument('-tey','--test_end_date', help='test end year', required=True)\n",
    "    \n",
    "#     args = vars(parser.parse_args())\n",
    "#     start_date = int(args['start_date'])\n",
    "#     end_date   = int(args['end_date'])\n",
    "#     test_start_date = int(args['test_start_date'])\n",
    "#     test_end_date   = int(args['test_end_date'])\n",
    "    start_date = 1950\n",
    "    end_date   = 1980\n",
    "    test_start_date = 1980\n",
    "    test_end_date   = 1985\n",
    "    \n",
    "    epochs = 200\n",
    "    batch_size = 32\n",
    "    lr= 0.001\n",
    "    \n",
    "    es = EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=25, restore_best_weights=True)\n",
    "    \n",
    "    secibert_embeddings  = load_obj('combined_reduced_tsne_embed')\n",
    "    \n",
    "    data, max_len = input_read()\n",
    "    train_data, test_data = train_test_data(data, start_date, end_date, test_start_date, test_end_date)\n",
    "    print(f\"train data: {train_data.shape[0]}, test data: {test_data.shape[0]}\")\n",
    "    train_graphs, train_graph_labels = graphs_data(secibert_embeddings, train_data)\n",
    "    test_graphs, test_graph_labels = graphs_data(secibert_embeddings, test_data)\n",
    "    \n",
    "    train_graph_labels = np.log2(np.array([g[-1] for g in train_graph_labels]))\n",
    "    test_graph_labels = np.log2(np.array([g[-1] for g in test_graph_labels]))\n",
    "    print(f\"train output: {train_graph_labels[0:5]}\")\n",
    "    print(f\"test output: {test_graph_labels[0:5]}\")\n",
    "    \n",
    "    train_generator = PaddedGraphGenerator(graphs=train_graphs)\n",
    "    \n",
    "    split_index = int(0.70*len(train_data))\n",
    "    train_index = range(0, split_index)\n",
    "    val_index  = range(split_index, len(train_data))\n",
    "\n",
    "    train_gen, val_gen = get_generators(train_generator, train_index, val_index, train_graph_labels, batch_size=batch_size)\n",
    "    test_gen= test_generator(test_graphs, test_graph_labels, batch_size)\n",
    "\n",
    "    model = create_graph_regression_model(train_generator, lr)\n",
    "\n",
    "\n",
    "    history, mse = train_model(model, train_gen, val_gen, es, epochs)\n",
    "    print(f\"Testing\")\n",
    "    test_error = model.evaluate(test_gen)[-1]\n",
    "    print(f\"val:{mse}, test error:{test_error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24883e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate(graphs, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
