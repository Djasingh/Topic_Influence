{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55d05d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gsdmm import MovieGroupProcess\n",
    "import texthero as hero\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df3e9a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../data/mgp_data/\"\n",
    "publication = pd.read_csv(folder+\"dblp_publication_data_for_mgp_researchers.csv\")\n",
    "publication[\"clean_title\"] = hero.clean(publication[\"title\"])\n",
    "publication[\"clean_title\"] = hero.stem(publication[\"clean_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7430a1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3140415, 7)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publication.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9e0ad2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "publication1 = publication.sample(1000000)\n",
    "titles = publication1[\"clean_title\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6389f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_to_words(titles):\n",
    "    for title in titles:\n",
    "        yield(gensim.utils.simple_preprocess(str(title), deacc=True))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0c781d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles1 = list(title_to_words(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a8ee7398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of all words in all documents\n",
    "dictionary = gensim.corpora.Dictionary(titles1)\n",
    "\n",
    "# filter extreme cases out of dictionary\n",
    "#dictionary.filter_extremes(no_below=5, no_above=0.5)\n",
    "\n",
    "# create variable containing length of dictionary/vocab\n",
    "vocab_length = len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a71435f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106186"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "979b5f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics_lists(model, top_clusters, n_words):\n",
    "    '''\n",
    "    Gets lists of words in topics as a list of lists.\n",
    "    \n",
    "    model: gsdmm instance\n",
    "    top_clusters:  numpy array containing indices of top_clusters\n",
    "    n_words: top n number of words to include\n",
    "    \n",
    "    '''\n",
    "    # create empty list to contain topics\n",
    "    topics = []\n",
    "    \n",
    "    # iterate over top n clusters\n",
    "    for cluster in top_clusters:\n",
    "        #create sorted dictionary of word distributions\n",
    "        sorted_dict = sorted(model.cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[:n_words]\n",
    "         \n",
    "        #create empty list to contain words\n",
    "        topic = []\n",
    "        \n",
    "        #iterate over top n words in topic\n",
    "        for k,v in sorted_dict:\n",
    "            #append words to topic list\n",
    "            topic.append(k)\n",
    "            \n",
    "        #append topics to topics list    \n",
    "        topics.append(topic)\n",
    "    \n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "09cab99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_topic = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c0ca96d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In stage 0: transferred 487453 clusters with 2 clusters populated\n",
      "In stage 1: transferred 449236 clusters with 2 clusters populated\n",
      "In stage 2: transferred 321339 clusters with 2 clusters populated\n",
      "In stage 3: transferred 141819 clusters with 2 clusters populated\n",
      "In stage 4: transferred 101026 clusters with 2 clusters populated\n",
      "In stage 5: transferred 94756 clusters with 2 clusters populated\n",
      "In stage 6: transferred 93815 clusters with 2 clusters populated\n",
      "In stage 7: transferred 93856 clusters with 2 clusters populated\n",
      "In stage 8: transferred 93606 clusters with 2 clusters populated\n",
      "In stage 9: transferred 93471 clusters with 2 clusters populated\n",
      "0.10915769171818648\n",
      "In stage 0: transferred 735606 clusters with 4 clusters populated\n",
      "In stage 1: transferred 678888 clusters with 4 clusters populated\n",
      "In stage 2: transferred 470570 clusters with 4 clusters populated\n",
      "In stage 3: transferred 221928 clusters with 4 clusters populated\n",
      "In stage 4: transferred 156920 clusters with 4 clusters populated\n",
      "In stage 5: transferred 146975 clusters with 4 clusters populated\n",
      "In stage 6: transferred 144467 clusters with 4 clusters populated\n",
      "In stage 7: transferred 143483 clusters with 4 clusters populated\n",
      "In stage 8: transferred 143046 clusters with 4 clusters populated\n",
      "In stage 9: transferred 142621 clusters with 4 clusters populated\n",
      "0.18730319525238684\n",
      "In stage 0: transferred 819268 clusters with 6 clusters populated\n",
      "In stage 1: transferred 756586 clusters with 6 clusters populated\n",
      "In stage 2: transferred 525285 clusters with 6 clusters populated\n",
      "In stage 3: transferred 287475 clusters with 6 clusters populated\n",
      "In stage 4: transferred 211619 clusters with 6 clusters populated\n",
      "In stage 5: transferred 188816 clusters with 6 clusters populated\n",
      "In stage 6: transferred 178694 clusters with 6 clusters populated\n",
      "In stage 7: transferred 175203 clusters with 6 clusters populated\n",
      "In stage 8: transferred 172978 clusters with 6 clusters populated\n",
      "In stage 9: transferred 171486 clusters with 6 clusters populated\n",
      "0.2872051228347223\n",
      "In stage 0: transferred 862569 clusters with 8 clusters populated\n",
      "In stage 1: transferred 796054 clusters with 8 clusters populated\n",
      "In stage 2: transferred 554310 clusters with 8 clusters populated\n",
      "In stage 3: transferred 332443 clusters with 8 clusters populated\n",
      "In stage 4: transferred 254164 clusters with 8 clusters populated\n",
      "In stage 5: transferred 225401 clusters with 8 clusters populated\n",
      "In stage 6: transferred 210969 clusters with 8 clusters populated\n",
      "In stage 7: transferred 200250 clusters with 8 clusters populated\n",
      "In stage 8: transferred 191934 clusters with 8 clusters populated\n",
      "In stage 9: transferred 185889 clusters with 8 clusters populated\n",
      "0.3472712342899078\n",
      "In stage 0: transferred 887480 clusters with 10 clusters populated\n",
      "In stage 1: transferred 824647 clusters with 10 clusters populated\n",
      "In stage 2: transferred 578445 clusters with 10 clusters populated\n",
      "In stage 3: transferred 330168 clusters with 10 clusters populated\n",
      "In stage 4: transferred 243173 clusters with 10 clusters populated\n",
      "In stage 5: transferred 211264 clusters with 10 clusters populated\n",
      "In stage 6: transferred 197861 clusters with 10 clusters populated\n",
      "In stage 7: transferred 192450 clusters with 10 clusters populated\n",
      "In stage 8: transferred 188527 clusters with 10 clusters populated\n",
      "In stage 9: transferred 186393 clusters with 10 clusters populated\n",
      "0.34372547395242903\n"
     ]
    }
   ],
   "source": [
    "cv_score = []\n",
    "num_topics = []\n",
    "for num_topic in range(2, 12, 2):\n",
    "    bow_corpus = [dictionary.doc2bow(doc) for doc in titles1]\n",
    "    \n",
    "    gsdmm = MovieGroupProcess(K=num_topic, alpha=0.1, beta=0.3, n_iters=10)\n",
    "    y = gsdmm.fit(titles1, vocab_length)\n",
    "    doc_count = np.array(gsdmm.cluster_doc_count)\n",
    "    top_index = doc_count.argsort()[-num_topic:][::-1]\n",
    "    \n",
    "    topics = get_topics_lists(gsdmm, top_index, 10)\n",
    "    cm_gsdmm = CoherenceModel(topics=topics, \n",
    "                              dictionary=dictionary, \n",
    "                              corpus=bow_corpus, \n",
    "                              texts=titles1, \n",
    "                              coherence='c_v')\n",
    "\n",
    "    # get coherence value\n",
    "    coherence_gsdmm = cm_gsdmm.get_coherence()  \n",
    "\n",
    "    print(coherence_gsdmm)\n",
    "    num_topics.append(num_topic)\n",
    "    cv_score.append(coherence_gsdmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "944643e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "907c974b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 2 : [('graph', 2207), ('problem', 1953), ('algorithm', 1790), ('method', 1425), ('optim', 1173), ('equat', 1081), ('comput', 1027), ('linear', 1025), ('function', 1014), ('approxim', 997)]\n",
      "\n",
      "Cluster 1 : [('system', 2881), ('base', 2680), ('model', 2191), ('data', 1699), ('use', 1341), ('comput', 1315), ('design', 1131), ('servic', 1130), ('applic', 1019), ('analysi', 987)]\n",
      "\n",
      "Cluster 6 : [('network', 4330), ('base', 2112), ('system', 1993), ('wireless', 1608), ('channel', 1321), ('effici', 1186), ('optim', 1115), ('use', 947), ('perform', 945), ('code', 923)]\n",
      "\n",
      "Cluster 9 : [('learn', 2587), ('base', 2285), ('network', 2061), ('use', 1702), ('model', 1629), ('data', 1151), ('detect', 1133), ('neural', 977), ('recognit', 950), ('imag', 879)]\n",
      "\n",
      "Cluster 8 : [('control', 1875), ('system', 1841), ('optim', 1408), ('base', 1391), ('model', 1292), ('time', 1115), ('network', 1093), ('algorithm', 871), ('dynam', 772), ('use', 705)]\n",
      "\n",
      "Cluster 3 : [('base', 2120), ('imag', 2000), ('use', 1714), ('model', 926), ('estim', 846), ('detect', 797), ('method', 688), ('data', 639), ('algorithm', 560), ('analysi', 538)]\n",
      "\n",
      "Cluster 7 : [('model', 530), ('base', 523), ('use', 492), ('imag', 394), ('network', 390), ('analysi', 379), ('data', 358), ('predict', 328), ('protein', 258), ('brain', 257)]\n",
      "\n",
      "Cluster 5 : [('intern', 701), ('proceed', 689), ('confer', 586), ('th', 558), ('workshop', 406), ('comput', 338), ('usa', 210), ('system', 199), ('symposium', 170), ('septemb', 152)]\n",
      "\n",
      "Cluster 0 : [('und', 256), ('von', 198), ('der', 195), ('fur', 155), ('ein', 136), ('zur', 101), ('die', 87), ('mit', 58), ('des', 56), ('im', 52)]\n",
      "\n",
      "Cluster 4 : [('de', 314), ('ji', 105), ('yu', 97), ('base', 73), ('des', 60), ('fa', 57), ('et', 57), ('algorithm', 48), ('la', 47), ('xing', 43)]\n"
     ]
    }
   ],
   "source": [
    "# define function to get top words per topic\n",
    "def top_words(cluster_word_distribution, top_cluster, values):\n",
    "    for cluster in top_cluster:\n",
    "        sort_dicts = sorted(cluster_word_distribution[cluster].items(), key=lambda k: k[1], reverse=True)[:values]\n",
    "        print(\"\\nCluster %s : %s\"%(cluster, sort_dicts))\n",
    "\n",
    "# get top words in topics\n",
    "top_words(gsdmm.cluster_word_distribution, top_index, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f990578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(doc_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2adeba5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, 4, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66aec0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2406536495851057\n"
     ]
    }
   ],
   "source": [
    "# evaluate model using Topic Coherence score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "15336302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.token2id[\"workshop\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d2e3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
